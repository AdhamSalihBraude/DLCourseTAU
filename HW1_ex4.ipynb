{"cells":[{"cell_type":"markdown","metadata":{"id":"TZG202gj0rjy"},"source":["\n","\n","\n","#**Ex.4 HW1 - Training LeNet-5 with pytorch**\n","\n","---\n"]},{"cell_type":"markdown","metadata":{"id":"f03mlLxw-taM"},"source":["# General setup"]},{"cell_type":"markdown","metadata":{"id":"UUSRqPSK7b3J"},"source":["\n","\n","```\n","# This is formatted as code\n","```\n","\n","Mounting the drive"]},{"cell_type":"code","execution_count":1,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":23893,"status":"ok","timestamp":1709463139618,"user":{"displayName":"Adham Salih","userId":"06947713781223928648"},"user_tz":-120},"id":"IPBkg6aG7hIH","outputId":"d2eeb77f-ed5f-44e0-f82a-cc40b08dff1f"},"outputs":[{"output_type":"stream","name":"stdout","text":["Mounted at /content/drive/\n"]}],"source":["from google.colab import drive\n","drive.mount('/content/drive/')"]},{"cell_type":"markdown","metadata":{"id":"Z4miWDV_03-7"},"source":["Installing all the needed lib.\n"]},{"cell_type":"code","execution_count":2,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":5208,"status":"ok","timestamp":1709463144820,"user":{"displayName":"Adham Salih","userId":"06947713781223928648"},"user_tz":-120},"id":"C3Fz9Ija0jKK","outputId":"57efabf7-f2e0-4474-cef3-12dca2359cf9"},"outputs":[{"output_type":"stream","name":"stdout","text":["Requirement already satisfied: torch in /usr/local/lib/python3.10/dist-packages (2.1.0+cu121)\n","Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (1.25.2)\n","Requirement already satisfied: torchvision in /usr/local/lib/python3.10/dist-packages (0.16.0+cu121)\n","Requirement already satisfied: matplotlib in /usr/local/lib/python3.10/dist-packages (3.7.1)\n","Requirement already satisfied: tabulate in /usr/local/lib/python3.10/dist-packages (0.9.0)\n","Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from torch) (3.13.1)\n","Requirement already satisfied: typing-extensions in /usr/local/lib/python3.10/dist-packages (from torch) (4.10.0)\n","Requirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from torch) (1.12)\n","Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch) (3.2.1)\n","Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch) (3.1.3)\n","Requirement already satisfied: fsspec in /usr/local/lib/python3.10/dist-packages (from torch) (2023.6.0)\n","Requirement already satisfied: triton==2.1.0 in /usr/local/lib/python3.10/dist-packages (from torch) (2.1.0)\n","Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from torchvision) (2.31.0)\n","Requirement already satisfied: pillow!=8.3.*,>=5.3.0 in /usr/local/lib/python3.10/dist-packages (from torchvision) (9.4.0)\n","Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib) (1.2.0)\n","Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.10/dist-packages (from matplotlib) (0.12.1)\n","Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib) (4.49.0)\n","Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib) (1.4.5)\n","Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib) (23.2)\n","Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib) (3.1.1)\n","Requirement already satisfied: python-dateutil>=2.7 in /usr/local/lib/python3.10/dist-packages (from matplotlib) (2.8.2)\n","Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil>=2.7->matplotlib) (1.16.0)\n","Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch) (2.1.5)\n","Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->torchvision) (3.3.2)\n","Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->torchvision) (3.6)\n","Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->torchvision) (2.0.7)\n","Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->torchvision) (2024.2.2)\n","Requirement already satisfied: mpmath>=0.19 in /usr/local/lib/python3.10/dist-packages (from sympy->torch) (1.3.0)\n"]}],"source":["!pip install torch numpy torchvision matplotlib tabulate"]},{"cell_type":"markdown","metadata":{"id":"3crNudwVxM1I"},"source":["[link text](https://)Adding (importing) the requried liberies"]},{"cell_type":"code","execution_count":3,"metadata":{"executionInfo":{"elapsed":7369,"status":"ok","timestamp":1709463152184,"user":{"displayName":"Adham Salih","userId":"06947713781223928648"},"user_tz":-120},"id":"vf-s0djAxKrh"},"outputs":[],"source":["import torch\n","import torch.nn as nn\n","import torch.nn.functional as F\n","import torchvision.datasets as dsets\n","import torchvision.transforms as transforms\n","import matplotlib.pyplot as plt\n","import numpy as np\n","from tabulate import tabulate"]},{"cell_type":"markdown","metadata":{"id":"f_Go7lhoxka-"},"source":["**Hyperparameters**"]},{"cell_type":"code","execution_count":4,"metadata":{"executionInfo":{"elapsed":7,"status":"ok","timestamp":1709463152184,"user":{"displayName":"Adham Salih","userId":"06947713781223928648"},"user_tz":-120},"id":"utIP26cexjN_"},"outputs":[],"source":["epochs = 25\n","batch_size = 100\n","learning_rate = 1e-3\n","Moment = 0.7 ## for SGD optimizer\n","optimizerType = 2 #1 for SGD and 2 for Adam\n","# Connect to GPU\n","device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n","dropoutPer = 0.1\n","WDparam = 1e-5 #from the paper or learning_rate / epochs"]},{"cell_type":"markdown","metadata":{"id":"enmD0nI9x2Tn"},"source":["**Dataset** loading"]},{"cell_type":"code","execution_count":5,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":6527,"status":"ok","timestamp":1709463159414,"user":{"displayName":"Adham Salih","userId":"06947713781223928648"},"user_tz":-120},"id":"IH4H22Vkx8kP","outputId":"27181db1-52f9-4d73-a2a6-e416d2f0f80d"},"outputs":[{"output_type":"stream","name":"stdout","text":["Downloading http://fashion-mnist.s3-website.eu-central-1.amazonaws.com/train-images-idx3-ubyte.gz\n","Downloading http://fashion-mnist.s3-website.eu-central-1.amazonaws.com/train-images-idx3-ubyte.gz to ./data/FashionMNIST/raw/train-images-idx3-ubyte.gz\n"]},{"output_type":"stream","name":"stderr","text":["100%|██████████| 26421880/26421880 [00:02<00:00, 12014594.80it/s]\n"]},{"output_type":"stream","name":"stdout","text":["Extracting ./data/FashionMNIST/raw/train-images-idx3-ubyte.gz to ./data/FashionMNIST/raw\n","\n","Downloading http://fashion-mnist.s3-website.eu-central-1.amazonaws.com/train-labels-idx1-ubyte.gz\n","Downloading http://fashion-mnist.s3-website.eu-central-1.amazonaws.com/train-labels-idx1-ubyte.gz to ./data/FashionMNIST/raw/train-labels-idx1-ubyte.gz\n"]},{"output_type":"stream","name":"stderr","text":["100%|██████████| 29515/29515 [00:00<00:00, 205152.70it/s]\n"]},{"output_type":"stream","name":"stdout","text":["Extracting ./data/FashionMNIST/raw/train-labels-idx1-ubyte.gz to ./data/FashionMNIST/raw\n","\n","Downloading http://fashion-mnist.s3-website.eu-central-1.amazonaws.com/t10k-images-idx3-ubyte.gz\n","Downloading http://fashion-mnist.s3-website.eu-central-1.amazonaws.com/t10k-images-idx3-ubyte.gz to ./data/FashionMNIST/raw/t10k-images-idx3-ubyte.gz\n"]},{"output_type":"stream","name":"stderr","text":["100%|██████████| 4422102/4422102 [00:01<00:00, 3819292.97it/s]\n"]},{"output_type":"stream","name":"stdout","text":["Extracting ./data/FashionMNIST/raw/t10k-images-idx3-ubyte.gz to ./data/FashionMNIST/raw\n","\n","Downloading http://fashion-mnist.s3-website.eu-central-1.amazonaws.com/t10k-labels-idx1-ubyte.gz\n","Downloading http://fashion-mnist.s3-website.eu-central-1.amazonaws.com/t10k-labels-idx1-ubyte.gz to ./data/FashionMNIST/raw/t10k-labels-idx1-ubyte.gz\n"]},{"output_type":"stream","name":"stderr","text":["100%|██████████| 5148/5148 [00:00<00:00, 19244453.65it/s]\n"]},{"output_type":"stream","name":"stdout","text":["Extracting ./data/FashionMNIST/raw/t10k-labels-idx1-ubyte.gz to ./data/FashionMNIST/raw\n","\n"]}],"source":["# FashionMNIST Dataset\n","train_dataset = dsets.FashionMNIST(root='./data',\n","                            train=True,\n","                            transform=transforms.ToTensor(),\n","                            download=True)\n","\n","test_dataset = dsets.FashionMNIST(root='./data',\n","                           train=False,\n","                           transform=transforms.ToTensor())\n","\n","# Data Loader (Input Pipeline)\n","train_loader = torch.utils.data.DataLoader(dataset=train_dataset,\n","                                           batch_size=batch_size,\n","                                           shuffle=True)\n","\n","test_loader = torch.utils.data.DataLoader(dataset=test_dataset,\n","                                          batch_size=batch_size,\n","                                          shuffle=False)\n"]},{"cell_type":"markdown","metadata":{"id":"hee4XwU70lyD"},"source":["#**LeNet-5 Classes**\n","\n","---\n","\n","\n","> diffrence from the original LeNet-5 paper\n","*   The network's structure is dapted to work with 28x28 images.\n","*   For the training, Cross-Entropy loss function is used.\n","*   Output layer uses softmax for caculating the probabilities.\n","*   Activation function : tanh -> ReLU"]},{"cell_type":"code","execution_count":6,"metadata":{"executionInfo":{"elapsed":6,"status":"ok","timestamp":1709463159414,"user":{"displayName":"Adham Salih","userId":"06947713781223928648"},"user_tz":-120},"id":"5hRNSdhxyIXB"},"outputs":[],"source":["# Neural Network Model (LeNet-5 for 28x28 image, ReLU as activation function)\n","class LeNet5(nn.Module):\n","    def __init__(self):\n","        super(LeNet5, self).__init__()\n","        # the 1st conv. Layer k = 5, Cout = 6 Cin = 1\n","        self.conv1 = nn.Conv2d(1, 6, 5) #24X24 feature map\n","         # pooling size 2\n","        self.pool = nn.MaxPool2d(2, 2) #12X12\n","        # the 2nd conv. Layer k = 5, Cout = 16 Cin = 6\n","        self.conv2 = nn.Conv2d(6, 16, 5) # 8X8 feature-Map , after the pooling 4X4\n","        # The 1st fully-connected Layer, Input size = 256, Output = 120\n","        self.fc1 = nn.Linear(16 * 4 * 4, 120)\n","        # The 2nd fully-connected Layer, Input size = 120, Output = 84\n","        self.fc2 = nn.Linear(120, 84)\n","        # The 3rd fully-connected Layer, Input size = 84, Output = 10\n","        self.fc3 = nn.Linear(84, 10)\n","        # dropout\n","\n","\n","    def forward(self, x):\n","\n","      #Activation func. is ReLU\n","        #claculation for the first conv. after pooling\n","        x = self.pool(F.relu(self.conv1(x)))\n","        #claculation for the first conv. after pooling\n","        x = self.pool(F.relu(self.conv2(x)))\n","        #represent x as 1d vector\n","        x = x.view(-1, 16 * 4 * 4) #for 32X32 images change to 5*5*16\n","        #applaying the fully cinnected layers (also ReLU activation)\n","        x = F.relu(self.fc1(x))\n","        x = F.relu(self.fc2(x))\n","        #x = self.fc3(x)\n","        x =  F.log_softmax(self.fc3(x), dim=1)\n","        return x"]},{"cell_type":"markdown","metadata":{"id":"8JQanvEz3Y58"},"source":["\n","\n","LeNet-5 with dropout"]},{"cell_type":"code","execution_count":7,"metadata":{"executionInfo":{"elapsed":5,"status":"ok","timestamp":1709463159414,"user":{"displayName":"Adham Salih","userId":"06947713781223928648"},"user_tz":-120},"id":"Gt_4jWhx2Ys0"},"outputs":[],"source":["class LeNet5D(nn.Module):\n","    def __init__(self,dropoutPer):\n","        super(LeNet5D, self).__init__()\n","        # the 1st conv. Layer k = 5, Cout = 6 Cin = 1\n","        self.conv1 = nn.Conv2d(1, 6, 5) #24X24 feature map\n","         # pooling size 2\n","        self.pool = nn.MaxPool2d(2, 2) #12X12\n","        # the 2nd conv. Layer k = 5, Cout = 16 Cin = 6\n","        self.conv2 = nn.Conv2d(6, 16, 5) # 8X8 feature-Map , after the pooling 4X4\n","        # The 1st fully-connected Layer, Input size = 256, Output = 120\n","        self.fc1 = nn.Linear(16 * 4 * 4, 120)\n","        # The 2nd fully-connected Layer, Input size = 120, Output = 84\n","        self.fc2 = nn.Linear(120, 84)\n","        # The 3rd fully-connected Layer, Input size = 84, Output = 10\n","        self.fc3 = nn.Linear(84, 10)\n","        # dropout\n","        self.dropout1d = nn.Dropout(p=dropoutPer)\n","        self.dropout2d = nn.Dropout2d(p=dropoutPer)\n","\n","    def forward(self, x):\n","\n","      #Activation func. is ReLU\n","        #x = self.dropoutIn(x)\n","        #claculation for the first conv. after pooling\n","        x = self.dropout2d(self.conv1(x))\n","        x = self.pool(F.relu(x))\n","        #claculation for the first conv. after pooling\n","        x = self.dropout2d(self.conv2(x))\n","        x = self.pool(F.relu(x))\n","        #represent x as 1d vector\n","        x = x.view(-1, 16 * 4 * 4) #for 32X32 images change to 5*5*16\n","        #applaying the fully cinnected layers (also ReLU activation)\n","        x = self.dropout1d(self.fc1(x))\n","        x = F.relu(x)\n","        x = self.dropout1d(self.fc2(x))\n","        x = F.relu(x)\n","        x =  F.log_softmax(self.fc3(x), dim=1)\n","        return x"]},{"cell_type":"markdown","metadata":{"id":"qKFiWlQ-AtoU"},"source":["LeNet with BN Class definition"]},{"cell_type":"code","execution_count":8,"metadata":{"executionInfo":{"elapsed":5,"status":"ok","timestamp":1709463159414,"user":{"displayName":"Adham Salih","userId":"06947713781223928648"},"user_tz":-120},"id":"o9pCG0aYAtoq"},"outputs":[],"source":["class LeNet5BN(nn.Module):\n","    def __init__(self):\n","        super(LeNet5BN, self).__init__()\n","        # the 1st conv. Layer k = 5, Cout = 6 Cin = 1\n","        self.conv1 = nn.Conv2d(1, 6, 5) #24X24 feature map\n","        self.bnconv1 = nn.BatchNorm2d(6)\n","         # pooling size 2\n","        self.pool = nn.MaxPool2d(2, 2) #12X12\n","        # the 2nd conv. Layer k = 5, Cout = 16 Cin = 6\n","        self.conv2 = nn.Conv2d(6, 16, 5) # 8X8 feature-Map , after the pooling 4X4\n","        self.bnconv2 = nn.BatchNorm2d(16)\n","        # The 1st fully-connected Layer, Input size = 256, Output = 120\n","        self.fc1 = nn.Linear(16 * 4 * 4, 120)\n","        self.bnfc1 = nn.BatchNorm1d(120)\n","        # The 2nd fully-connected Layer, Input size = 120, Output = 84\n","        self.fc2 = nn.Linear(120, 84)\n","        self.bnfc2 = nn.BatchNorm1d(84)\n","        # The 3rd fully-connected Layer, Input size = 84, Output = 10\n","        self.fc3 = nn.Linear(84, 10)\n","        # BN\n","\n","\n","\n","    def forward(self, x):\n","\n","      #Activation func. is ReLU\n","        #claculation for the first conv. after pooling\n","        x = self.bnconv1(self.conv1(x))\n","        x = self.pool(F.relu(x))\n","\n","\n","        #x = self.pool(self.bnconv1(F.relu(self.conv1(x))))\n","        #claculation for the first conv. after pooling\n","\n","        x = self.bnconv2(self.conv2(x))\n","        x = self.pool(F.relu(x))\n","        #x = self.pool(self.bnconv2(F.relu(self.conv2(x))))\n","        #represent x as 1d vector\n","        x = x.view(-1, 16 * 4 * 4) #for 32X32 images change to 5*5*16\n","        #applaying the fully cinnected layers (also ReLU activation)\n","        x = self.bnfc1(self.fc1(x))\n","        x = F.relu(x)\n","        x = self.bnfc2(self.fc2(x))\n","        x = F.relu(x)\n","\n","        #x = self.bnfc1(F.relu(self.fc1(x)))\n","        #x = self.bnfc2(F.relu(self.fc2(x)))\n","        #x = self.fc3(x)\n","        x =  F.log_softmax(self.fc3(x), dim=1)\n","        return x"]},{"cell_type":"markdown","metadata":{"id":"4ZjwchUhyPt-"},"source":["\n","\n","# Traning function"]},{"cell_type":"code","execution_count":8,"metadata":{"executionInfo":{"elapsed":4,"status":"ok","timestamp":1709463159414,"user":{"displayName":"Adham Salih","userId":"06947713781223928648"},"user_tz":-120},"id":"FmmayfjIwIEP"},"outputs":[],"source":[]},{"cell_type":"code","execution_count":9,"metadata":{"executionInfo":{"elapsed":4,"status":"ok","timestamp":1709463159415,"user":{"displayName":"Adham Salih","userId":"06947713781223928648"},"user_tz":-120},"id":"jceiCpmjyUdv"},"outputs":[],"source":["def TrainNN(model,device,epochs,optimizer,criterion,train_loader,test_loader):\n","  AccTrainList = []\n","  AccTestList = []\n","  train_losses, test_losses = [], []\n","  # Train the network\n","  for e in range(epochs):\n","    running_loss = 0\n","    for i, (images, labels) in enumerate(train_loader):\n","      images, labels = images.to(device), labels.to(device)\n","      optimizer.zero_grad()\n","      loss = criterion(model(images), labels)\n","      loss.backward()\n","      optimizer.step()\n","      running_loss += loss.item()\n","    else:\n","      test_loss = 0\n","      accTest = 0\n","      train_loss = 0\n","      accTrain = 0\n","      with torch.no_grad():\n","        model.eval()\n","        for images, labels in test_loader:\n","          images, labels = images.to(device), labels.to(device)\n","          log_ps = model(images)\n","          test_loss += criterion(log_ps, labels)\n","          #ps = log_ps\n","          ps = torch.exp(log_ps)\n","          top_p, top_class = ps.topk(1, dim=1)\n","          equals = top_class == labels.view(*top_class.shape)\n","          accTest += torch.mean(equals.type(torch.FloatTensor))\n","        for images, labels in train_loader:\n","          images, labels = images.to(device), labels.to(device)\n","          log_ps = model(images)\n","          train_loss += criterion(log_ps, labels)\n","          ps = torch.exp(log_ps)\n","          top_p, top_class = ps.topk(1, dim=1)\n","          equals = top_class == labels.view(*top_class.shape)\n","          accTrain += torch.mean(equals.type(torch.FloatTensor))\n","    print('>> epoch: {}, train_loss: {:.3f}, test_loss: {:.3f}, train_Acc: {:.1f}, test_Acc: {:.1f} ' .format(e+1, train_loss/len(train_loader),test_loss/len(test_loader),100*accTrain/len(train_loader),100*accTest/len(test_loader)))\n","    model.train()\n","    train_losses.append(train_loss/len(train_loader))\n","    test_losses.append(test_loss/len(test_loader))\n","    AccTrainList.append(accTrain/len(train_loader))\n","    AccTestList.append(accTest/len(test_loader))\n","  del loss\n","  return model,AccTestList,AccTrainList,test_losses,train_losses"]},{"cell_type":"markdown","metadata":{"id":"wf1tABmb0heQ"},"source":["# ***Training without regularization***"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"background_save":true,"base_uri":"https://localhost:8080/"},"id":"T1MEFPUu2DzL","outputId":"a9c5cfe0-94ad-4226-a6dd-32b20445a5b0"},"outputs":[{"output_type":"stream","name":"stdout","text":["Start Training\n",">> epoch: 1, train_loss: 0.528, test_loss: 0.550, train_Acc: 79.9, test_Acc: 78.9 \n",">> epoch: 2, train_loss: 0.435, test_loss: 0.461, train_Acc: 84.2, test_Acc: 83.0 \n",">> epoch: 3, train_loss: 0.370, test_loss: 0.400, train_Acc: 86.5, test_Acc: 85.5 \n",">> epoch: 4, train_loss: 0.340, test_loss: 0.372, train_Acc: 87.5, test_Acc: 86.6 \n",">> epoch: 5, train_loss: 0.325, test_loss: 0.360, train_Acc: 88.0, test_Acc: 86.8 \n"]}],"source":["modelNoReg = LeNet5().to(device)\n","# Loss\n","criterion = nn.CrossEntropyLoss()\n","#Optimizer\n","if optimizerType == 1:\n","  optimizer = torch.optim.SGD(modelNoReg.parameters(),lr=learning_rate,momentum= Moment)\n","else:\n","  optimizer = torch.optim.Adam(modelNoReg.parameters(),lr=learning_rate)\n","modelNoReg.train()\n","print('Start Training')\n","modelNoReg,AccTestList,AccTrainList,test_losses,train_losses = TrainNN(modelNoReg,device,epochs,optimizer,criterion,train_loader,test_loader)\n","print('Finished Training')\n","# Save the Model\n","torch.save(modelNoReg.state_dict(), '/content/drive/My Drive/ex1_300746930_034915504/models/LeNet5model.pkl')\n","#plot\n","plt.plot(range(1,epochs+1),train_losses, label = 'Train')\n","plt.plot(range(1,epochs+1),test_losses, label = 'Test')\n","plt.xticks(np.arange(0, epochs+1, 2.0))\n","plt.ylabel('lossValue')\n","plt.xlabel('epochs')\n","plt.legend()\n","plt.title('Loss')\n","plt.grid(True)\n","plt.figure()\n","plt.plot(range(1,epochs+1),AccTrainList, label ='Train')\n","plt.plot(range(1,epochs+1),AccTestList, label ='Test')\n","plt.ylabel('AccValue')\n","plt.xticks(np.arange(0, epochs+1, 2.0))\n","plt.xlabel('epochs')\n","plt.title('Acc')\n","plt.grid(True)\n","plt.legend()\n","plt.show()"]},{"cell_type":"markdown","metadata":{"id":"uoqYnleH_EUB"},"source":["# ***Training with dropout***"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"background_save":true},"id":"MVP7vFvA_Qvb"},"outputs":[],"source":["modelDropout = LeNet5D(dropoutPer).to(device)\n","# Loss\n","criterion = nn.CrossEntropyLoss()\n","#Optimizer\n","if optimizerType == 1:\n","  optimizer = torch.optim.SGD(modelDropout.parameters(),lr=learning_rate,momentum= Moment)\n","else:\n","  optimizer = torch.optim.Adam(modelDropout.parameters(),lr=learning_rate)\n","modelDropout.train()\n","print('Start Training')\n","modelDropout,AccTestListD,AccTrainListD,test_lossesD,train_lossesD = TrainNN(modelDropout,device,epochs,optimizer,criterion,train_loader,test_loader)\n","print('Finished Training')\n","# Save the Model\n","torch.save(modelDropout.state_dict(), '/content/drive/My Drive/ex1_300746930_034915504/models/LeNet5modelDropout.pkl')\n","#plot\n","plt.plot(range(1,epochs+1),train_lossesD, label = 'Train')\n","plt.plot(range(1,epochs+1),test_lossesD, label = 'Test')\n","plt.ylabel('lossValue')\n","plt.xlabel('epochs')\n","plt.legend()\n","plt.xticks(np.arange(0, epochs+1, 2.0))\n","plt.title('Loss With Dropout')\n","plt.grid(True)\n","plt.figure()\n","plt.plot(range(1,epochs+1),AccTrainListD, label ='Train')\n","plt.plot(range(1,epochs+1),AccTestListD, label ='Test')\n","plt.ylabel('AccValue')\n","plt.xticks(np.arange(0, epochs+1, 2.0))\n","plt.xlabel('epochs')\n","plt.title('Acc With Dropout')\n","plt.grid(True)\n","plt.legend()\n","plt.show()"]},{"cell_type":"markdown","metadata":{"id":"zrmCu2jq_Soq"},"source":["# ***Training with Weight Decay***"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"background_save":true},"id":"YJHLQqeo_erW"},"outputs":[],"source":["\n","modelWD = LeNet5().to(device)\n","# Loss\n","criterion = nn.CrossEntropyLoss()\n","#Optimizer\n","if optimizerType == 1:\n","  optimizer = torch.optim.SGD(modelWD.parameters(),lr=learning_rate,momentum= Moment,weight_decay = WDparam)\n","else:\n","  optimizer = torch.optim.Adam(modelWD.parameters(),lr=learning_rate,weight_decay = WDparam)\n","modelWD.train()\n","print('Start Training')\n","modelWD,AccTestListWD,AccTrainListWD,test_lossesWD,train_lossesWD = TrainNN(modelWD,device,epochs,optimizer,criterion,train_loader,test_loader)\n","print('Finished Training')\n","# Save the Model\n","torch.save(modelWD.state_dict(), '/content/drive/My Drive/ex1_300746930_034915504/models/LeNet5WDmodel.pkl')\n","#plot\n","plt.plot(range(1,epochs+1),train_lossesWD, label = 'Train')\n","plt.plot(range(1,epochs+1),test_lossesWD, label = 'Test')\n","plt.ylabel('lossValue')\n","plt.xlabel('epochs')\n","plt.legend()\n","plt.xticks(np.arange(0, epochs+1, 2.0))\n","plt.title('Loss with Weight Decay')\n","plt.grid(True)\n","plt.figure()\n","plt.plot(range(1,epochs+1),AccTrainListWD, label ='Train')\n","plt.plot(range(1,epochs+1),AccTestListWD, label ='Test')\n","plt.xticks(np.arange(0, epochs+1, 2.0))\n","plt.ylabel('AccValue')\n","plt.xlabel('epochs')\n","plt.title('Acc with Weight Decay')\n","plt.grid(True)\n","plt.legend()\n","plt.show()"]},{"cell_type":"markdown","metadata":{"id":"hcM5MZ3o_fsi"},"source":["# ***Training With Batch Normalization***"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"background_save":true},"id":"eUqJw_fxAto8"},"outputs":[],"source":["modelBN = LeNet5BN().to(device)\n","# Loss\n","criterion = nn.CrossEntropyLoss()\n","#Optimizer\n","if optimizerType == 1:\n","  optimizer = torch.optim.SGD(modelBN.parameters(),lr=learning_rate,momentum= Moment)\n","else:\n","  optimizer = torch.optim.Adam(modelBN.parameters(),lr=learning_rate)\n","modelBN.train()\n","print('Start Training')\n","modelBN,AccTestListBN,AccTrainListBN,test_lossesBN,train_lossesBN = TrainNN(modelBN,device,epochs,optimizer,criterion,train_loader,test_loader)\n","print('Finished Training')\n","\n","# Save the Model\n","torch.save(modelBN.state_dict(), '/content/drive/My Drive/ex1_300746930_034915504/models/LeNet5modelBN.pkl')\n","#plot\n","plt.plot(range(1,epochs+1),train_lossesBN, label = 'Train')\n","plt.plot(range(1,epochs+1),test_lossesBN, label = 'Test')\n","plt.ylabel('lossValue')\n","plt.xlabel('epochs')\n","plt.legend()\n","plt.xticks(np.arange(0, epochs+1, 2.0))\n","plt.title('Loss With BN')\n","plt.grid(True)\n","plt.figure()\n","plt.plot(range(1,epochs+1),AccTrainListBN, label ='Train')\n","plt.plot(range(1,epochs+1),AccTestListBN, label ='Test')\n","plt.ylabel('AccValue')\n","plt.xlabel('epochs')\n","plt.xticks(np.arange(0, epochs+1, 2.0))\n","plt.title('Acc With BN')\n","plt.grid(True)\n","plt.legend()\n","plt.show()"]},{"cell_type":"markdown","metadata":{"id":"52JZggVrydF6"},"source":["# ***Accuracy Caculation and Comparison (for Saved Models)***\n","\n","\n","Run the following sections including the sub-sections\n","1.   General setup\n","2.   LeNet-5 Classes\n","\n","\n"]},{"cell_type":"markdown","metadata":{"id":"-j-oK2vVFH2k"},"source":["## load a saved models\n","First mount the drive and check the modele path.\n","\n"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"background_save":true},"id":"WPM3ohiUBXWP"},"outputs":[],"source":["modelNoReg = LeNet5().to(device)\n","modelNoReg.load_state_dict(torch.load('/content/drive/My Drive/ex1_300746930_034915504/models/LeNet5model.pkl'))\n","\n","modelDropout = LeNet5D(dropoutPer).to(device)\n","modelDropout.load_state_dict(torch.load('/content/drive/My Drive/ex1_300746930_034915504/models/LeNet5modelDropout.pkl'))\n","\n","modelWD = LeNet5().to(device)\n","modelWD.load_state_dict(torch.load('/content/drive/My Drive/ex1_300746930_034915504/models/LeNet5WDmodel.pkl'))\n","\n","modelBN = LeNet5BN().to(device)\n","modelBN.load_state_dict(torch.load('/content/drive/My Drive/ex1_300746930_034915504/models/LeNet5modelBN.pkl'))\n"]},{"cell_type":"markdown","metadata":{"id":"zVYe1OerzEIc"},"source":["## Test and compare the models"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"background_save":true},"id":"evP4S-WxzNrW"},"outputs":[],"source":["accTestNR = 0\n","accTestD = 0\n","accTestWD = 0\n","accTestBN = 0\n","modelNoReg.eval()\n","modelDropout.eval()\n","modelWD.eval()\n","modelBN.eval()\n","for images, labels in test_loader:\n","  images, labels = images.to(device), labels.to(device)\n","\n","  log_psNR = modelNoReg(images)\n","  psNR = torch.exp(log_psNR)\n","  top_pNR, top_classNR = psNR.topk(1, dim=1)\n","  equalsNR = top_classNR == labels.view(*top_classNR.shape)\n","  accTestNR += torch.mean(equalsNR.type(torch.FloatTensor))\n","\n","  log_psD = modelDropout(images)\n","  psD = torch.exp(log_psD)\n","  top_pD, top_classD = psD.topk(1, dim=1)\n","  equalsD = top_classD == labels.view(*top_classD.shape)\n","  accTestD += torch.mean(equalsD.type(torch.FloatTensor))\n","\n","  log_psWD = modelWD(images)\n","  psWD = torch.exp(log_psWD)\n","  top_pWD, top_classWD = psWD.topk(1, dim=1)\n","  equalsWD = top_classWD == labels.view(*top_classWD.shape)\n","  accTestWD += torch.mean(equalsWD.type(torch.FloatTensor))\n","\n","  log_psBN = modelBN(images)\n","  psBN = torch.exp(log_psBN)\n","  top_pBN, top_classBN = psBN.topk(1, dim=1)\n","  equalsBN = top_classBN == labels.view(*top_classBN.shape)\n","  accTestBN += torch.mean(equalsBN.type(torch.FloatTensor))\n","\n","accTrainNR = 0\n","accTrainD = 0\n","accTrainWD = 0\n","accTrainBN = 0\n","for images, labels in train_loader:\n","  images, labels = images.to(device), labels.to(device)\n","\n","  log_psNR = modelNoReg(images)\n","  psNR = torch.exp(log_psNR)\n","  top_pNR, top_classNR = psNR.topk(1, dim=1)\n","  equalsNR = top_classNR == labels.view(*top_classNR.shape)\n","  accTrainNR += torch.mean(equalsNR.type(torch.FloatTensor))\n","\n","  log_psD = modelDropout(images)\n","  psD = torch.exp(log_psD)\n","  top_pD, top_classD = psD.topk(1, dim=1)\n","  equalsD = top_classD == labels.view(*top_classD.shape)\n","  accTrainD += torch.mean(equalsD.type(torch.FloatTensor))\n","\n","  log_psWD = modelWD(images)\n","  psWD = torch.exp(log_psWD)\n","  top_pWD, top_classWD = psWD.topk(1, dim=1)\n","  equalsWD = top_classWD == labels.view(*top_classWD.shape)\n","  accTrainWD += torch.mean(equalsWD.type(torch.FloatTensor))\n","\n","  log_psBN = modelBN(images)\n","  psBN = torch.exp(log_psBN)\n","  top_pBN, top_classBN = psBN.topk(1, dim=1)\n","  equalsBN = top_classBN == labels.view(*top_classBN.shape)\n","  accTrainBN += torch.mean(equalsBN.type(torch.FloatTensor))\n","C1 = 100/len(test_loader)\n","C2 = 100/len(train_loader)\n","T = tabulate([['Without Regularization', C1*accTestNR, C2*accTrainNR],\n","              ['Dropout', C1*accTestD, C2*accTrainD],\n","              ['Weight Decay', C1*accTestWD, C2*accTrainWD],\n","              ['Batch Normalization', C1*accTestBN, C2*accTrainBN]]\n","             ,headers=['Model', 'Test-accuracy ', 'Train-accuracy'])\n","print(T)"]}],"metadata":{"accelerator":"GPU","colab":{"provenance":[],"gpuType":"T4"},"kernelspec":{"display_name":"Python 3","name":"python3"}},"nbformat":4,"nbformat_minor":0}